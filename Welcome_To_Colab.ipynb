{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rey2512/Model/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4hYJvPUiDiH6",
        "outputId": "75fad0d2-5b53-4c5d-f0dc-e65997f32ef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from timm import create_model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/1DeepFake/splitted_data\"\n",
        "TRAIN_REAL_PATH = os.path.join(BASE_PATH, \"real/train\")\n",
        "TRAIN_FAKE_PATH = os.path.join(BASE_PATH, \"fake/train\")\n",
        "VAL_REAL_PATH   = os.path.join(BASE_PATH, \"real/val\")\n",
        "VAL_FAKE_PATH   = os.path.join(BASE_PATH, \"fake/val\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "class DeepFakeDataset(Dataset):\n",
        "    def __init__(self, file_list, labels, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        cap = cv2.VideoCapture(path)\n",
        "        ret, frame = cap.read()\n",
        "        cap.release()\n",
        "        if not ret:\n",
        "            frame = np.zeros((299, 299, 3), dtype=np.uint8)\n",
        "        frame = cv2.resize(frame, (299, 299))\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            frame = self.transform(frame)\n",
        "        label = self.labels[idx]\n",
        "        return frame, label\n"
      ],
      "metadata": {
        "id": "PP-Cdm7ND4Ue",
        "outputId": "165ba5bf-0ad2-4fd2-8566-1e5bc23d6e13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect file paths\n",
        "train_real = [os.path.join(TRAIN_REAL_PATH, f) for f in os.listdir(TRAIN_REAL_PATH) if f.endswith(\".mp4\")]\n",
        "train_fake = [os.path.join(TRAIN_FAKE_PATH, f) for f in os.listdir(TRAIN_FAKE_PATH) if f.endswith(\".mp4\")]\n",
        "val_real   = [os.path.join(VAL_REAL_PATH, f) for f in os.listdir(VAL_REAL_PATH) if f.endswith(\".mp4\")]\n",
        "val_fake   = [os.path.join(VAL_FAKE_PATH, f) for f in os.listdir(VAL_FAKE_PATH) if f.endswith(\".mp4\")]\n",
        "\n",
        "print(\"Train Real:\", len(train_real), \"Train Fake:\", len(train_fake))\n",
        "print(\"Val Real:\", len(val_real), \"Val Fake:\", len(val_fake))\n",
        "\n",
        "if len(train_real)==0 or len(train_fake)==0:\n",
        "    raise Exception(\"❌ ERROR: Training folders are empty.\")\n",
        "\n",
        "# Combine all paths and labels\n",
        "train_files = train_real + train_fake\n",
        "train_labels = [0]*len(train_real) + [1]*len(train_fake)\n",
        "val_files = val_real + val_fake\n",
        "val_labels = [0]*len(val_real) + [1]*len(val_fake)\n",
        "\n",
        "# Create Datasets\n",
        "train_dataset = DeepFakeDataset(train_files, train_labels, transform)\n",
        "val_dataset   = DeepFakeDataset(val_files, val_labels, transform)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Model\n",
        "model = create_model(\"xception\", pretrained=True, num_classes=2).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Validation Accuracy: {100*correct/total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ATFKkHpyD6PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3bac26-11bd-4e20-9405-3688d82fc831"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Real: 280 Train Fake: 560\n",
            "Val Real: 80 Val Fake: 160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth\" to /root/.cache/torch/hub/checkpoints/xception-43020ad28.pth\n",
            "Epoch [1/3] Loss: 0.5422\n",
            "Validation Accuracy: 78.33%\n",
            "Epoch [2/3] Loss: 0.1521\n",
            "Validation Accuracy: 82.50%\n",
            "Epoch [3/3] Loss: 0.0685\n",
            "Validation Accuracy: 83.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your trained model\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/1DeepFake/best_deepfake_detector2.pth\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transformation for Xception input\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Xception input size\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Video path\n",
        "video_path = \"/content/drive/MyDrive/1DeepFake/test_video2.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fake_frames = 0\n",
        "real_frames = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to PIL image\n",
        "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # Model prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(img)\n",
        "        prediction = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    if prediction == 0:\n",
        "        real_frames += 1\n",
        "    else:\n",
        "        fake_frames += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# Overall Video Prediction\n",
        "print(f\"Total Frames: {frame_count}\")\n",
        "print(f\"Real Frames: {real_frames}, Fake Frames: {fake_frames}\")\n",
        "\n",
        "if fake_frames > real_frames:\n",
        "    print(\"❌ The video is FAKE\")\n",
        "else:\n",
        "    print(\"✅ The video is REAL\")\n"
      ],
      "metadata": {
        "id": "GuRj_8DhD98w",
        "outputId": "da8f1f50-30e7-4102-9750-df2c51796580",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Frames: 443\n",
            "Real Frames: 46, Fake Frames: 397\n",
            "❌ The video is FAKE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "juLFcFhBqbFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}